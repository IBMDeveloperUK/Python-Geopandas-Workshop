{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Explore UK Crime Data with Pandas and GeoPandas\n\n\n## Table of Contents\n\n1. [Introduction to GeoPandas](#geopandas)<br>\n2. [Getting ready](#ready)<br>\n3. [London boroughs](#boroughs)<br>\n    3.1. [Load data](#load1)<br>\n    3.2. [Explore data](#explore1)<br>\n4. [Crime data](#crime)<br>\n    4.1. [Load data](#load2)<br>\n    4.2. [Explore data](#explore2)<br>\n5. [OSM data](#osm)<br>\n    5.1. [Load data](#load3)<br>\n    5.2. [Explore data](#explore3)<br>"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString, Polygon\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"geopandas\"></a>\n## 1. Introduction to GeoPandas\n\n> If you have not used Pandas before, please read through this [10 minute tutorial](http://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) or check out this [workshop](https://github.com/IBMDeveloperUK/pandas-workshop/blob/master/README.md).\n\nA GeoDataSeries or GeoDataFrame is very similar to a Pandas DataFrame, but has an additional column with the geometry. You can load a file, or create your own:"}, {"metadata": {}, "cell_type": "code", "source": "df = pd.DataFrame({'city':       ['London','Manchester','Birmingham','Leeds','Glasgow'],\n        'population': [9787426,  2553379,     2440986,    1777934, 1209143],\n        'area':       [1737.9,   630.3,       598.9,      487.8,   368.5 ],\n        'latitude':   [51.50853, 53.48095,    52.48142,   53.79648,55.86515],\n        'longitude':  [-0.12574, -2.23743,    -1.89983,   -1.54785,-4.25763]})\n\ndf['geometry']  = list(zip(df.longitude, df.latitude))\n\ndf['geometry'] = df['geometry'].apply(Point)\n\ncities = gpd.GeoDataFrame(df, geometry='geometry')\ncities.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Creating a basic map is similar to creating a plot from a Pandas DataFrame:"}, {"metadata": {}, "cell_type": "code", "source": "cities.plot(column='population');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "As `cities` is a DataFrame you can apply data manipulations, for instance:"}, {"metadata": {}, "cell_type": "code", "source": "cities['population'].mean()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Points vs Lines vs Polygons\n\nWe need some more data! Create Points by squeezing out the geometry for each city:"}, {"metadata": {}, "cell_type": "code", "source": "lon_point = cities.loc[cities['city'] == 'London', 'geometry'].squeeze()\nman_point = cities.loc[cities['city'] == 'Manchester', 'geometry'].squeeze()\nbirm_point = cities.loc[cities['city'] == 'Birmingham', 'geometry'].squeeze()\nleeds_point = cities.loc[cities['city'] == 'Leeds', 'geometry'].squeeze()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Lines between 2 cities by creating a LineString between 2 points:"}, {"metadata": {}, "cell_type": "code", "source": "lon_man_line = gpd.GeoSeries(LineString([lon_point, man_point]))\nman_birm_line = gpd.GeoSeries(LineString([man_point, birm_point]))\nbirm_lon_line = gpd.GeoSeries(LineString([birm_point,lon_point]))\nleeds_man_line = gpd.GeoSeries(LineString([leeds_point, man_point]))\nbirm_leeds_line = gpd.GeoSeries(LineString([birm_point,leeds_point]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "A polygon between 3 cities by creating a Polygon between 3 points:"}, {"metadata": {}, "cell_type": "code", "source": "Polygon([[lon_point.x,lon_point.y],[man_point.x,man_point.y],[lon_point.x,lon_point.y]])\nlon_man_birm_polygon = gpd.GeoSeries(Polygon([[lon_point.x,lon_point.y],[man_point.x,man_point.y],[birm_point.x,birm_point.y],[lon_point.x,lon_point.y]]))\nleeds_man_birm_polygon = gpd.GeoSeries(Polygon([[leeds_point.x,leeds_point.y],[man_point.x,man_point.y],[birm_point.x,birm_point.y]]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "And plot all of them together:"}, {"metadata": {}, "cell_type": "code", "source": "fig, (poly1,poly2) = plt.subplots(ncols=2, sharex=True, sharey=True)\n\nlon_man_birm_polygon.plot(ax=poly1, color='lightblue', edgecolor='black',alpha=0.5);\nlon_man_line.plot(ax=poly1,color='violet',alpha=0.5);\nman_birm_line.plot(ax=poly1,color='blue',alpha=0.5);\nbirm_lon_line.plot(ax=poly1,color='green',alpha=0.5);\n\nleeds_man_birm_polygon.plot(ax=poly2, color='yellow', edgecolor='black',alpha=0.5);\nleeds_man_line.plot(ax=poly2,color='red',alpha=0.5);\nman_birm_line.plot(ax=poly2,color='blue',alpha=0.5);\nbirm_leeds_line.plot(ax=poly2,color='green',alpha=0.5);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Overlay\n\nWith overlay you can combine geometries, for instance union, difference, symmetrical difference and intersection are some of the operations that can be performed.\n\nLet's combine the 2 polygons:"}, {"metadata": {}, "cell_type": "code", "source": "poly1 = gpd.GeoDataFrame({'geometry': lon_man_birm_polygon})\npoly2 = gpd.GeoDataFrame({'geometry': leeds_man_birm_polygon})\n\ngpd.overlay( poly1, poly2, how='union').plot(color='red',alpha=0.5);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Buffer"}, {"metadata": {}, "cell_type": "code", "source": "cities1 = cities[0:1].copy()\ncities1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "base = cities1.buffer(3).plot(color='blue',alpha=0.5);\ncities1.buffer(2).plot(ax=base,color='green',alpha=0.5);\ncities1.buffer(1).plot(ax=base,color='yellow',alpha=0.5);\ncities1.plot(ax=base,color='red',alpha=0.5);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "##### Spatial relationships\n\nThere are several functions to check geospatial relationships: `equals`, `contains`, `crosses`, `disjoint`,`intersects`,`overlaps`,`touches`,`within` and `covers`. These all use `shapely`: read more [here](https://shapely.readthedocs.io/en/stable/manual.html#predicates-and-relationships) and some more background [here](https://en.wikipedia.org/wiki/Spatial_relation).\n\nA few examples:"}, {"metadata": {}, "cell_type": "code", "source": "cities.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cities1.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cities1.contains(lon_point)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cities1[cities1.contains(lon_point)]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cities[cities.contains(man_point)]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The inverse of `contains`:"}, {"metadata": {}, "cell_type": "code", "source": "cities[cities.within(cities1)]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cities[cities.disjoint(lon_point)]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"ready\"></a>\n## 2. Getting ready\n\n### 2.1. Add data to Cloud Object Store (COS)\nThe data for this workshop needs to be added to your project. Go to the GitHub repo and download the files in the [data folder](https://github.com/IBMDeveloperUK/python-geopandas-workshop/tree/master/data) to your machine. \n\nAdd the files in the data menu on the right of the notebook (click the 1010 button  at the top right if you do not see this) into COS:\n\n- boundaries.zip\n- 2018-1-metropolitan-street.zip\n- 2018-2-metropolitan-street.zip\n- 2018-metropolitan-stop-and-search.zip\n- london_inner_pois.zip\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### 2.2. Project Access token\n\nAs the data files are not simple csv files, we need a little trick to load the data. The first thing you need is a project access token to programmatically access COS.\n\nClick the 3 dots at the top of the notebook to insert the project token that you created earlier. This will create a new cell in the notebook that you will need to run first before continuing with the rest of the notebook. If you are sharing this notebook you should remove this cell, else anyone can use you Cloud Object Storage from this project.\n\n> If you cannot find the new cell it is probably at the top of this notebook. Scroll up, run the cell and continue with section 2.3"}, {"metadata": {}, "cell_type": "markdown", "source": "### 2.3. Helper function to load data into notebook\n\nThe second thing you need to load data into the notebook is the below help function. Data will be copied to the local project space and loaded from there. The below helper function will do this for you. "}, {"metadata": {}, "cell_type": "code", "source": "# define the helper function \ndef download_file_to_local(project_filename, local_file_destination=None, project=None):\n    \"\"\"\n    Uses project-lib to get a bytearray and then downloads this file to local.\n    Requires a valid `project` object.\n    \n    Args:\n        project_filename str: the filename to be passed to get_file\n        local_file_destination: the filename for the local file if different\n        \n    Returns:\n        0 if everything worked\n    \"\"\"\n    \n    project = project\n    \n    # get the file\n    print(\"Attempting to get file {}\".format(project_filename))\n    _bytes = project.get_file(project_filename).read()\n    \n    # check for new file name, download the file\n    print(\"Downloading...\")\n    if local_file_destination==None: local_file_destination = project_filename\n    \n    with open(local_file_destination, 'wb') as f: \n        f.write(bytearray(_bytes))\n        print(\"Completed writing to {}\".format(local_file_destination))\n        \n    return 0", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"boroughs\"></a>\n## 3. London boroughs\n\n<a id=\"load1\"></a>\n### 3.1. Load data\n\nGeospatial data comes in many formats, but with GeoPandas you can read most files with just one command. For example this geojson file with the London boroughs:"}, {"metadata": {}, "cell_type": "code", "source": "# load data from a url\nboroughs = gpd.read_file(\"https://skgrange.github.io/www/data/london_boroughs.json\")\nboroughs.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"explore1\"></a>\n### 3.2. Explore data\n\nTo plot a basic map add `.plot()` to a geoDataFrame.  "}, {"metadata": {}, "cell_type": "code", "source": "boroughs.plot();", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "boroughs.plot(column='code');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "boroughs.plot(column='area_hectares');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Dissolve\n\nThe boroughs are made up of many districts that you might want to combine. For this example this can be done by adding a new column and then use `.dissolve()`:"}, {"metadata": {}, "cell_type": "code", "source": "boroughs['all'] = 1\nallboroughs = boroughs.dissolve(by='all',aggfunc='sum')\nallboroughs.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "allboroughs.plot();", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To change the size of the map and remove the box around the map, run the below:"}, {"metadata": {}, "cell_type": "code", "source": "[fig, ax] = plt.subplots(1, figsize=(10, 6))\nallboroughs.plot(ax=ax);\nax.axis('off');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Join\n\nLet's join this with some more data: "}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv('https://raw.githubusercontent.com/IBMDeveloperUK/python-pandas-workshop/master/london-borough-profiles.csv',encoding = 'unicode_escape')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The columns to join the two tables on are `code` and `Code`. To use the join method, first the index of both tables has to be set to this column.\n\nThe below adds the columns from `df` to `boroughs`:\n"}, {"metadata": {}, "cell_type": "code", "source": "boroughs = boroughs.set_index('code').join(df.set_index('Code'))\nboroughs.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "boroughs2 = boroughs.dissolve(by='Inner/_Outer_London',aggfunc='mean')\n\n[fig, ax] = plt.subplots(1, figsize=(10, 6))\nboroughs2.plot(column='id', cmap='Paired', linewidth=0.5, edgecolor='black', legend=False, ax=ax);\nax.axis('off');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Below is a map of the average gender pay gap for each borough. \n\n* add a new column `paygap`\n* define the size of the plot\n* plot the background \n* add the paygap data and a title"}, {"metadata": {}, "cell_type": "code", "source": "boroughs['paygap'] =((boroughs['Gross_Annual_Pay_-_Male_(2016)'] - boroughs['Gross_Annual_Pay_-_Female_(2016)'])/ \\\n    boroughs['Gross_Annual_Pay_-_Male_(2016)']) * 100\n\n[fig,ax] = plt.subplots(1, figsize=(12, 8))\n\nboroughs.plot(ax=ax, color=\"lightgrey\", edgecolor='black', linewidth=0.5)\n\nboroughs.dropna().plot(column='paygap', cmap='Reds', edgecolor='black', linewidth=0.5,\n               legend=True, ax=ax);\nax.axis('off');\nax.set_title('Gender pay gap in London (2016)');", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"crime\"></a>\n## 4. Crime data\n\nThe crime data is pre-processed in this [notebook](https://github.com/IBMDeveloperUK/geopandas-workshop/blob/master/notebooks/prepare-uk-crime-data.ipynb) so it is easier to read here. We will only look at data from 2018.\n\nData is downloaded from https://data.police.uk/ ([License](https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/))\n\n<a id=\"load2\"></a>\n### 4.1. Load data\n\nThis dataset cannot be loaded into a geoDataFrame directly. Instead the data is loaded into a DataFrame and then converted:"}, {"metadata": {}, "cell_type": "code", "source": "download_file_to_local('2018-1-metropolitan-street.zip', project=project)\ndownload_file_to_local('2018-2-metropolitan-street.zip', project=project)\nstreet = pd.read_csv(\"./2018-1-metropolitan-street.zip\")\nstreet2 = pd.read_csv(\"./2018-2-metropolitan-street.zip\")\nstreet = street.append(street2) ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "download_file_to_local('2018-metropolitan-stop-and-search.zip', project=project)\nstop_search = pd.read_csv(\"./2018-metropolitan-stop-and-search.zip\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Clean up of the local directory:"}, {"metadata": {}, "cell_type": "code", "source": "! rm *.zip", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "street.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "stop_search.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Convert to geoDataFrames"}, {"metadata": {}, "cell_type": "code", "source": "street['coordinates'] = list(zip(street.Longitude, street.Latitude))\nstreet['coordinates'] = street['coordinates'].apply(Point)\nstreet = gpd.GeoDataFrame(street, geometry='coordinates')\nstreet.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "stop_search['coordinates'] = list(zip(stop_search.Longitude, stop_search.Latitude))\nstop_search['coordinates'] = stop_search['coordinates'].apply(Point)\nstop_search = gpd.GeoDataFrame(stop_search, geometry='coordinates')\nstop_search.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"explore2\"></a>\n### 4.2. Explore data\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data with Pandas. There are no right or wrong answers, the questions below give you some suggestions at what to look at. <br/> \n   <ul>\n  <li>How much data is there? Is this changing over time? Can you plot this? </li>\n  <li>Are there missing values? Should these rows be deleted?  </li>\n  <li>Which columns of the datasets contain useful information? What kind of categories are there and are they all meaningful?</li>\n  <li>Which crimes occur most often? And near which location?</li>\n  <li>Is there anything you want to explore further or are curious about? Is there any data that you will need for this?</li>      \n  <li>Notice anything odd about the latitude and longitudes? Read here how the data is anonymised: https://data.police.uk/about/.</li>       \n  </ul> \n    \n  Uncomment and run the cells starting with '# %load' to see some of the things that we came up with. Run each cell twice, once to load the code and then again to run the code.  \n</div>  "}, {"metadata": {}, "cell_type": "code", "source": "# your data exploration (add as many cells as you need by clicking the `+` at the top of the notebook)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer1.py\nprint ('rows in street: '+str(len(street)))\n\n# columns \nprint ('Columns: '+str(street.columns))\n\n# categories\nprint ('Crime type: '+str(street['Crime type'].unique()))\nprint ('Last outcome category: '+str(street['Last outcome category'].unique()))\nprint (street['Context'].unique())\n\n# delete columns\nstreet = street.drop(columns=['Unnamed: 0','Latitude', 'Longitude','Context'])\n\n# convert Date to datetime\nstreet['Month'] = street['Month'].apply(lambda x: datetime.strptime(x, \"%Y-%m\"))\n\nstreet.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer2.py\nbystreet = street.groupby(['Location','Crime type']).count()\nbystreet = bystreet.drop(columns=['Month', 'Last outcome category','coordinates','LSOA code'])\nbystreet = bystreet.rename(index=str, columns={\"Crime ID\": \"Number of crimes\"})\n\nbystreet.sort_values(by=['Number of crimes'], ascending=False).head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer3.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer4.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer5.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Some things we noticed:\n* The number of stop and searches seems to go up. That is something you could investigate further. Is any of the categories increasing? \n* Another interesting question is how the object of search and the outcome are related. Are there types of searches where nothing is found more frequently? \n* In the original files there are also columns of gender, age range and ethnicity. If you want to explore this further you can change the code and re-process the data from this [notebook](https://github.com/IBMDeveloperUK/geopandas-workshop/blob/master/notebooks/prepare-uk-crime-data.ipynb) and use the full dataset.\n* And how could you combine the two datasets?\n\n### Spatial join\n\n> The below solution was found [here](https://gis.stackexchange.com/questions/306674/geopandas-spatial-join-and-count) after googling for 'geopandas count points in polygon'\n\nThe coordinate system (`crs`) needs to be the same for both GeoDataFrames. "}, {"metadata": {}, "cell_type": "code", "source": "print(boroughs.crs)\nprint(stop_search.crs)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Add a borough to each point with a spatial join. This will add the `geometry` and other columns from `boroughs2` to the points in `stop_search`. "}, {"metadata": {}, "cell_type": "code", "source": "stop_search.crs = boroughs.crs\ndfsjoin = gpd.sjoin(boroughs,stop_search) \ndfsjoin.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Then aggregate this table by creating a [pivot table](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html) where for each borough the number of  categories in `Object of search` are counted. Then drop the pivot level and remove the index, so you can merge this new table back into the `boroughs2` DataFrame."}, {"metadata": {}, "cell_type": "code", "source": "dfpivot = pd.pivot_table(dfsjoin,index='id',columns='Object of search',aggfunc={'Object of search':'count'})\ndfpivot.columns = dfpivot.columns.droplevel()\ndfpivot = dfpivot.reset_index()\ndfpivot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "boroughs3 = boroughs.merge(dfpivot, how='left',on='id')\nboroughs3.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's make some maps!"}, {"metadata": {}, "cell_type": "code", "source": "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n\np1=boroughs3.plot(column='Controlled drugs',ax=axs[0],cmap='Blues',legend=True);\naxs[0].set_title('Controlled drugs', fontdict={'fontsize': '12', 'fontweight' : '5'});\n\np2=boroughs3.plot(column='Stolen goods',ax=axs[1], cmap='Reds',legend=True);\naxs[1].set_title('Stolen goods', fontdict={'fontsize': '12', 'fontweight' : '5'});\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data with GeoPandas. Again there are no right or wrong answers, the questions below give you some suggestions at what to look at. <br/> \n   <ul>\n  <li>Improve the above maps. How many arrests are there in each borough? Use the above method but first select only the arrests using the column 'Outcome'. Can you plot this? </li>\n  <li>Are there changes over time? Is there a difference between months? Use `street` and look at Westminster or another borough where the crime rate seems higher. </li>    \n  </ul> \n</div>  "}, {"metadata": {}, "cell_type": "code", "source": "# your data exploration (add as many cells as you need)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer6.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# %load https://raw.githubusercontent.com/IBMDeveloperUK/python-geopandas-workshop/master/answers/answer7.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"osm\"></a>\n## 5. OSM data\n\nThe Open Street Map data is also pre-processed in this [notebook]() so it is easier to read into this notebook. \n\nData is downloaded from http://download.geofabrik.de/europe/great-britain.html and more details decription of the data is [here](http://download.geofabrik.de/osm-data-in-gis-formats-free.pdf).\n\n<a id=\"load3\"></a>\n### 5.1. Load data"}, {"metadata": {}, "cell_type": "code", "source": "download_file_to_local('london_inner_pois.zip', project=project)\npois = gpd.read_file(\"zip://./london_inner_pois.zip\")\npois.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"explore3\"></a>\n### 5.2. Explore data"}, {"metadata": {}, "cell_type": "code", "source": "pois.size", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pois['fclass'].unique()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Count and plot the number of pubs by borough:"}, {"metadata": {}, "cell_type": "code", "source": "pubs = pois[pois['fclass']=='pub']\n\npubs2 = gpd.sjoin(boroughs,pubs) \npubs3 = pd.pivot_table(pubs2,index='id',columns='fclass',aggfunc={'fclass':'count'})\npubs3.columns = pubs3.columns.droplevel()\npubs3 = pubs3.reset_index()\nboroughs5 = boroughs.merge(pubs3, left_on='id',right_on='id')\n\nboroughs5.plot(column='pub',cmap='Blues',legend=True);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<div class=\"alert alert-success\">\n <b>EXERCISE</b> <br/> \n Explore the data further. Again there are no right or wrong answers, the questions below give you some suggestions at what to look at. <br/> \n   <ul>\n  <li> Is there a category of POIs that relates to the number of crimes? You might have to aggregate the data on a different more detailed level for this one. </li>\n  <li> Can you find if there is a category of POIs that related to the number of crimes?  </li>\n  <li> Count the number of crimes around a certain POI. Choose a point and use the buffer function from the top of the notebook. But note that the crimes are anonymised, so the exact location is not given, only an approximation.  </li>\n       \n  </ul> \n</div>  "}, {"metadata": {}, "cell_type": "code", "source": "# answers\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Hopefully you got an idea of the possibilities with geospatial data now. There is a lot more to explore with this data. Let us know if you find anything interesting! We are on Twitter as @MargrietGr and @yaminigrao"}, {"metadata": {}, "cell_type": "markdown", "source": "\n\n\nCopyright \u00a9 2019 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}